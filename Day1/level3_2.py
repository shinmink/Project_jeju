import re
import requests
from bs4 import BeautifulSoup

# 1. HTML ê°€ì ¸ì˜¤ê¸°
url = "https://quotes.toscrape.com/"
print(f"[1] URL ì ‘ì† ì¤‘: {url}")

try:
    html = requests.get(url, timeout=5).text
    print("[2] HTML ë¡œë”© ì„±ê³µ âœ…")
except Exception as e:
    print(f"[ì˜¤ë¥˜] ìš”ì²­ ì‹¤íŒ¨: {e}")
    exit()

# 2. íŒŒì‹±
soup = BeautifulSoup(html, "html.parser")
print("[3] HTML íŒŒì‹± ì™„ë£Œ âœ…")

# 3. quote ë¸”ë¡ ì¶”ì¶œ
quotes = soup.find_all("div", class_="quote")
print(f"[4] ì¸ìš©êµ¬ ê°œìˆ˜: {len(quotes)}ê°œ")

# 4. ê° ì¸ìš©êµ¬ì—ì„œ í…ìŠ¤íŠ¸ì™€ ì €ì ì¶”ì¶œ
for i, q in enumerate(quotes, 1):
    text = q.find("span", class_="text").get_text(strip=True)
    author = q.find("small", class_="author").string
    print(f"ğŸ’¬ {i}. {text} - {author}")

# 5. ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ì™¸ë¶€ ë§í¬ ì¶”ì¶œ (http ë˜ëŠ” httpsë¡œ ì‹œì‘)
external_links = soup.find_all("a", href=re.compile(r"^https?://"))
print(f"\n[5] ì™¸ë¶€ ë§í¬ ê°œìˆ˜: {len(external_links)}ê°œ")
for i, a in enumerate(external_links, 1):
    print(f"ğŸŒ ì™¸ë¶€ ë§í¬ {i}: {a['href']}")

# 6. CSS ì„ íƒì í™œìš©: div.tags ë‚´ë¶€ì˜ a.tag
tag_elems = soup.select("div.tags a.tag")   # div.tags ë‚´ë¶€ì˜ a.tag ì „ë¶€ ì„ íƒ
tags = sorted({t.string for t in tag_elems})
print(f"\n[6] ì´ í˜ì´ì§€ì— ë“±ì¥í•œ íƒœê·¸ë“¤: {', '.join(tags)}")