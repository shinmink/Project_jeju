from bs4 import BeautifulSoup
import requests

# 1. ìš”ì²­í•  URL
url = "https://example.com"
print(f"[1] URL ì ‘ì†: {url}")

# 2. ì›¹ í˜ì´ì§€ ìš”ì²­ (ê¸°ë³¸ GET)
res = requests.get(url)
print(f"[2] ì‘ë‹µ ìƒíƒœ ì½”ë“œ: {res.status_code}")
res.raise_for_status()

# 3. BeautifulSoupìœ¼ë¡œ íŒŒì‹±
# â€» ê¸°ë³¸ html.parser ì‚¬ìš©, ë‹¤ë¥¸ íŒŒì„œ ì„ íƒì§€ëŠ” ì•„ë˜ì— ì„¤ëª…
soup = BeautifulSoup(res.text, "html.parser")
# soup = BeautifulSoup(res.text, "lxml")       # ì†ë„ ë¹ ë¦„ (ì„¤ì¹˜ í•„ìš”: pip install lxml)
# soup = BeautifulSoup(res.text, "html5lib")   # HTML5 ì™„ë²½ íŒŒì‹± (ì„¤ì¹˜ í•„ìš”: pip install html5lib)

print("[3] HTML íŒŒì‹± ì™„ë£Œ âœ…")

# 4. ì œëª© íƒœê·¸ (ì˜ˆ: <h1>) ê°€ì ¸ì˜¤ê¸°
title_tag = soup.find('h1')
if title_tag:
    print(f"[4] í˜ì´ì§€ ì œëª© (h1): {title_tag.text.strip()}")
else:
    print("[4] í˜ì´ì§€ì— <h1> íƒœê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.")

# 5. ëª¨ë“  ë§í¬ (<a> íƒœê·¸) ê°€ì ¸ì˜¤ê¸°
links = soup.find_all('a')
print(f"[5] ë§í¬ ìˆ˜: {len(links)}ê°œ")

# 6. ë§í¬ ëª©ë¡ ì¶œë ¥ (ìµœëŒ€ 20ê°œë§Œ ë¯¸ë¦¬ë³´ê¸°)
for i, link in enumerate(links[:20]):
    href = link.get('href')
    text = link.get_text(strip=True)
    print(f"ğŸ”— {i+1:>2}. í…ìŠ¤íŠ¸: {text or '(í…ìŠ¤íŠ¸ ì—†ìŒ)'}")
    print(f"     â†’ ë§í¬: {href}")

print("[6] í¬ë¡¤ë§ ì™„ë£Œ ğŸ‰")